{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import string\n",
    "import json\n",
    "sys.path.append('../../')\n",
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import redirect_stdout\n",
    "# brain2brain\n",
    "from brain2brain import utils\n",
    "from brain2brain import generators\n",
    "from brain2brain import tcn_experiments\n",
    "# TCN\n",
    "from brain2brain.tcn import TCN\n",
    "from brain2brain.tcn import compiled_tcn\n",
    "# TF\n",
    "\n",
    "from tensorflow.keras import backend as K, Model, Input, optimizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GRU, Lambda, TimeDistributed, Activation\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tmarcu/brain2brain/experiments/notebooks'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../experiment_params/tcn_experiment_m2m_2.json\") as f:\n",
    "    experiment_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36853, 114)\n"
     ]
    }
   ],
   "source": [
    "path = experiment_dict['path']\n",
    "batch_size = experiment_dict['batch_size']\n",
    "epochs = experiment_dict['epochs']\n",
    "lookback_window = experiment_dict['lookback_window']\n",
    "length_pred = experiment_dict['length_pred']\n",
    "delay_pred = experiment_dict['delay_pred']\n",
    "samples_per_second = experiment_dict['samples_per_second']\n",
    "electrode_selection=experiment_dict['electrode_selection']\n",
    "debug_mode = experiment_dict['debug_mode']\n",
    "num_feat = experiment_dict['num_feat']\n",
    "num_classes = experiment_dict['num_classes']\n",
    "nb_filters = experiment_dict['nb_filters']\n",
    "kernel_size = experiment_dict['kernel_size']\n",
    "dilations=experiment_dict['dilations']\n",
    "nb_stacks = experiment_dict['nb_stacks']\n",
    "output_len = experiment_dict['output_len']\n",
    "padding = experiment_dict['padding']\n",
    "use_skip_connections = experiment_dict['use_skip_connections']\n",
    "return_sequences = experiment_dict['return_sequences']\n",
    "regression = experiment_dict['regression']\n",
    "dropout_rate = experiment_dict['dropout_rate']\n",
    "name = experiment_dict['name']\n",
    "kernel_initializer = experiment_dict['kernel_initializer']\n",
    "activation = experiment_dict['activation']\n",
    "opt = experiment_dict['opt']\n",
    "lr = experiment_dict['lr']\n",
    "# Read saved paths for training.\n",
    "saved_paths = utils.get_file_paths(path)\n",
    "# Split the train files into a training and validation set.\n",
    "train, val = utils.split_file_paths(saved_paths, 0.8)\n",
    "total_electrode_count = utils.get_file_shape(train[0])[1]\n",
    "# Electrodes\n",
    "electrode_count = len(electrode_selection)\n",
    "# Sampling of electrodes.\n",
    "timesteps_per_sample = int(lookback_window // samples_per_second)\n",
    "# Training Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Generator\n",
    "train_generator = generators.FGenerator(file_paths=train,\n",
    "                                        lookback=lookback_window, length=length_pred, delay=delay_pred,\n",
    "                                        batch_size=batch_size, sample_period=samples_per_second,\n",
    "                                        electrodes=electrode_selection, shuffle=True, debug=debug_mode)\n",
    "# Validation Generator\n",
    "val_generator = generators.FGenerator(file_paths=val,\n",
    "                                      lookback=lookback_window, length=length_pred, delay=delay_pred,\n",
    "                                      batch_size=batch_size, sample_period=samples_per_second,\n",
    "                                      electrodes=electrode_selection, shuffle=False, debug=debug_mode)\n",
    "train_steps = len(train_generator)\n",
    "val_steps = len(val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"/home/tmarcu/brain2brain/experiment_logs/tcn_experiment_m2m_2/model.h5\",\n",
    "                   custom_objects={\"TCN\": TCN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 193s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(val_generator, steps=val_steps,\n",
    "                            callbacks=None, max_queue_size=10, workers=1,\n",
    "                            use_multiprocessing=True, verbose=1)\n",
    "predictions_path = \"predictions.json\"\n",
    "np.save(predictions_path, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104448, 1, 5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04569653, -0.06815685, -0.06594924, -0.04025666, -0.02818307]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.82527386, -0.27210556,  0.03552958,  0.23143432, -0.36599276]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
