{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import redirect_stdout\n",
    "from pathlib import Path\n",
    "# brain2brain\n",
    "from brain2brain import utils\n",
    "from brain2brain import generators\n",
    "# TCN\n",
    "from brain2brain.tcn import TCN\n",
    "from brain2brain.tcn import compiled_tcn\n",
    "# TF\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GRU, Lambda, TimeDistributed, RepeatVector\n",
    "# Wandb\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_for_electrode(electrode = 0):\n",
    "    experiment_dict = {\n",
    "        \"experiment_name\": \"gru_o2o_sweep_676_bin_norm\",\n",
    "        \"experiment_description\" : \"Attempting to predict signals for all electrodes in order to better understand which ones work. All hyperparameters below get passed to hyperparameters_defaults.\",\n",
    "        \"target_folder\" : \"gru_o2o_sweep_676_bin_norm/\",\n",
    "        \"train_path\" : \"/home/tmarcu/brain2brain/brain2brain/train_676_bin_norm_2.txt\",\n",
    "        \"val_path\" : \"/home/tmarcu/brain2brain/brain2brain/val_676_bin_norm_2.txt\",\n",
    "        \"batch_size\" : 512,\n",
    "        \"epochs\" : 128,\n",
    "        \"early_stopping_patience\": 2,\n",
    "        \"lookback_window\" : 15,\n",
    "        \"length_pred\" : 3,\n",
    "        \"delay_pred\" : 0,\n",
    "        \"electrode\" : 0,\n",
    "        \"activation\" : \"relu\",\n",
    "        \"samples_per_second\" : 1,\n",
    "        \"return_sequences\" : True,\n",
    "        \"debug_mode\" : False,\n",
    "        \"hidden_units\": 100,\n",
    "        \"dropout_rate\": 0.05,\n",
    "        \"recurrent_dropout\": 0.05,\n",
    "        \"activation\" : \"linear\",\n",
    "        \"opt\" : \"adam\",\n",
    "        \"loss\" : \"mse\"\n",
    "    }\n",
    "\n",
    "    experiment_name = experiment_dict['experiment_name']\n",
    "    experiment_description = experiment_dict['experiment_description']\n",
    "    target_folder = experiment_dict['target_folder']\n",
    "\n",
    "    # Ensure target directory exists.\n",
    "    try:\n",
    "        Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "    except IOError:\n",
    "        print(f\"Directory creation failed for path {target_folder}\")\n",
    "\n",
    "    # Save dictionary in json as well\n",
    "    utils.save_json_file(experiment_dict, target_folder + \"experiment_params.json\")\n",
    "    # Configure wandb\n",
    "    # Toggle Offline Mode\n",
    "    os.environ['WANDB_MODE'] = 'dryrun'\n",
    "    wandb.init(name=experiment_name,\n",
    "                notes=experiment_description,\n",
    "                config=experiment_dict,\n",
    "                dir=target_folder,\n",
    "                entity=\"theodormarcu\",\n",
    "                project=\"brain2brain\")\n",
    "\n",
    "    # Save Hyperparams\n",
    "    config = wandb.config\n",
    "    # Read saved paths for training.\n",
    "    # saved_paths = utils.get_file_paths(config.path)\n",
    "    train_paths = utils.get_file_paths(config.train_path)\n",
    "    val_paths = utils.get_file_paths(config.val_path)\n",
    "    # Split the train files into a training and validation set.\n",
    "    # train, val = utils.split_file_paths(saved_paths, 0.8)\n",
    "    total_electrode_count = utils.get_file_shape(train_paths[0])[1]\n",
    "    # Electrodes\n",
    "    electrode_count = 1\n",
    "    # Sampling of electrodes.\n",
    "    timesteps_per_sample = int(config.lookback_window // config.samples_per_second)\n",
    "    # Training Generator\n",
    "    train_generator = generators.FGenerator(file_paths=train_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=True,\n",
    "                                            debug=config.debug_mode)\n",
    "    # Validation Generator\n",
    "    val_generator = generators.FGenerator(file_paths=val_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=False,\n",
    "                                            debug=config.debug_mode)\n",
    "\n",
    "    train_steps = len(train_generator)\n",
    "    val_steps = len(val_generator)\n",
    "\n",
    "    print(f\"Train Generator Batch Shape:\\n\"\n",
    "            f\"Sample={train_generator[0][0].shape} Pred={train_generator[0][1].shape}\")\n",
    "    print(f\"Validation Generator Batch Shape:\\n\"\n",
    "            f\"Sample={val_generator[0][0].shape} Pred={val_generator[0][1].shape}\")\n",
    "\n",
    "    callbacks_list = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=2,\n",
    "            mode=\"min\"\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=target_folder+\"model_checkpoint.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        WandbCallback(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_model=True,\n",
    "        )\n",
    "    ]\n",
    "    # GRU One-to-one Architecture\n",
    "    model = Sequential()\n",
    "    model.add(GRU(config.hidden_units,\n",
    "                  activation=config.activation,\n",
    "                  return_sequences=config.return_sequences,\n",
    "                  input_shape=(config.lookback_window, 1),\n",
    "                  dropout=config.dropout_rate,\n",
    "                  recurrent_dropout=config.recurrent_dropout))\n",
    "    print(model.output_shape)\n",
    "    model.add(GRU(config.hidden_units, activation=config.activation))\n",
    "    model.add(Dense(config.length_pred))\n",
    "    model.compile(optimizer=config.opt, loss=config.loss)\n",
    "    model.summary()\n",
    "\n",
    "    # Save Model Config and Architecture\n",
    "    utils.save_json_file(model.get_config(), target_folder + \"model_config.json\")\n",
    "    utils.save_json_file(model.to_json(), target_folder + \"model_architecture.json\")\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                    steps_per_epoch=train_steps,\n",
    "                                    epochs=config.epochs,\n",
    "                                    callbacks=callbacks_list,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=val_steps)\n",
    "\n",
    "    model.save(target_folder + \"model.h5\")\n",
    "    model.save_weights(target_folder + 'model_weights.h5')\n",
    "    # Save History to File (For Later)\n",
    "    utils.save_json_file(history.history, target_folder + \"history.json\")\n",
    "    # Plot Loss Curves for Validation and Training\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "    plt.title(f\"Training and Validation Loss. Electrode {config.electrode}\")\n",
    "    plt.savefig(target_folder + \"train_val_loss_plot.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_28 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 177ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 166ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 33s 188ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 165ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 30s 175ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 169ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 181ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 30s 171ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 181ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 167ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 32s 185ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 28s 164ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 32s 185ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 168ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_22 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 177ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 169ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_24 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_25 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 179ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 166ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_for_electrode_seq2seq(electrode = 0):\n",
    "    experiment_dict = {\n",
    "        \"experiment_name\": \"gru_o2o_sweep_676_bin_norm_seq2seq\",\n",
    "        \"experiment_description\" : \"Attempting to predict signals for all electrodes in order to better understand which ones work. All hyperparameters below get passed to hyperparameters_defaults.\",\n",
    "        \"target_folder\" : \"gru_o2o_sweep_676_bin_norm_seq2seq/\",\n",
    "        \"train_path\" : \"/home/tmarcu/brain2brain/brain2brain/train_676_bin_norm_2.txt\",\n",
    "        \"val_path\" : \"/home/tmarcu/brain2brain/brain2brain/val_676_bin_norm_2.txt\",\n",
    "        \"batch_size\" : 512,\n",
    "        \"epochs\" : 128,\n",
    "        \"early_stopping_patience\": 2,\n",
    "        \"lookback_window\" : 15,\n",
    "        \"length_pred\" : 3,\n",
    "        \"delay_pred\" : 0,\n",
    "        \"electrode\" : 0,\n",
    "        \"activation\" : \"relu\",\n",
    "        \"samples_per_second\" : 1,\n",
    "        \"return_sequences\" : True,\n",
    "        \"debug_mode\" : False,\n",
    "        \"hidden_units\": 100,\n",
    "        \"dropout_rate\": 0.05,\n",
    "        \"recurrent_dropout\": 0.05,\n",
    "        \"activation\" : \"linear\",\n",
    "        \"opt\" : \"adam\",\n",
    "        \"loss\" : \"mse\"\n",
    "    }\n",
    "\n",
    "    experiment_name = experiment_dict['experiment_name']\n",
    "    experiment_description = experiment_dict['experiment_description']\n",
    "    target_folder = experiment_dict['target_folder']\n",
    "\n",
    "    # Ensure target directory exists.\n",
    "    try:\n",
    "        Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "    except IOError:\n",
    "        print(f\"Directory creation failed for path {target_folder}\")\n",
    "\n",
    "    # Save dictionary in json as well\n",
    "    utils.save_json_file(experiment_dict, target_folder + \"experiment_params.json\")\n",
    "    # Configure wandb\n",
    "    # Toggle Offline Mode\n",
    "    os.environ['WANDB_MODE'] = 'dryrun'\n",
    "    wandb.init(name=experiment_name,\n",
    "                notes=experiment_description,\n",
    "                config=experiment_dict,\n",
    "                dir=target_folder,\n",
    "                entity=\"theodormarcu\",\n",
    "                project=\"brain2brain\")\n",
    "\n",
    "    # Save Hyperparams\n",
    "    config = wandb.config\n",
    "    # Read saved paths for training.\n",
    "    # saved_paths = utils.get_file_paths(config.path)\n",
    "    train_paths = utils.get_file_paths(config.train_path)\n",
    "    val_paths = utils.get_file_paths(config.val_path)\n",
    "    # Split the train files into a training and validation set.\n",
    "    # train, val = utils.split_file_paths(saved_paths, 0.8)\n",
    "    total_electrode_count = utils.get_file_shape(train_paths[0])[1]\n",
    "    # Electrodes\n",
    "    electrode_count = 1\n",
    "    # Sampling of electrodes.\n",
    "    timesteps_per_sample = int(config.lookback_window // config.samples_per_second)\n",
    "    # Training Generator\n",
    "    train_generator = generators.FGenerator(file_paths=train_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=True,\n",
    "                                            debug=config.debug_mode)\n",
    "    # Validation Generator\n",
    "    val_generator = generators.FGenerator(file_paths=val_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=False,\n",
    "                                            debug=config.debug_mode)\n",
    "\n",
    "    train_steps = len(train_generator)\n",
    "    val_steps = len(val_generator)\n",
    "\n",
    "    print(f\"Train Generator Batch Shape:\\n\"\n",
    "            f\"Sample={train_generator[0][0].shape} Pred={train_generator[0][1].shape}\")\n",
    "    print(f\"Validation Generator Batch Shape:\\n\"\n",
    "            f\"Sample={val_generator[0][0].shape} Pred={val_generator[0][1].shape}\")\n",
    "\n",
    "    callbacks_list = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=2,\n",
    "            mode=\"min\"\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=target_folder+\"model_checkpoint.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        WandbCallback(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_model=True,\n",
    "        )\n",
    "    ]\n",
    "    # GRU One-to-one Architecture\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(config.lookback_window, 1)))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.summary()\n",
    "\n",
    "    # Save Model Config and Architecture\n",
    "    utils.save_json_file(model.get_config(), target_folder + \"model_config.json\")\n",
    "    utils.save_json_file(model.to_json(), target_folder + \"model_architecture.json\")\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                    steps_per_epoch=train_steps,\n",
    "                                    epochs=config.epochs,\n",
    "                                    callbacks=callbacks_list,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=val_steps)\n",
    "\n",
    "    model.save(target_folder + \"model.h5\")\n",
    "    model.save_weights(target_folder + 'model_weights.h5')\n",
    "    # Save History to File (For Later)\n",
    "    utils.save_json_file(history.history, target_folder + \"history.json\")\n",
    "    # Plot Loss Curves for Validation and Training\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "    plt.title(f\"Training and Validation Loss. Electrode {config.electrode}\")\n",
    "    plt.savefig(target_folder + \"train_val_loss_plot.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-bd99aa253be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_experiment_for_electrode_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-ea31d51037ff>\u001b[0m in \u001b[0;36mrun_experiment_for_electrode_seq2seq\u001b[0;34m(electrode)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mval_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     print(f\"Train Generator Batch Shape:\\n\"\n\u001b[0m\u001b[1;32m     89\u001b[0m             f\"Sample={train_generator[0][0].shape} Pred={train_generator[0][1].shape}\")\n\u001b[1;32m     90\u001b[0m     print(f\"Validation Generator Batch Shape:\\n\"\n",
      "\u001b[0;32m~/brain2brain/brain2brain/generators.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectrode_output_ix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             y = np.empty((self.batch_size, math.ceil(\n\u001b[0;32m--> 186\u001b[0;31m                 self.length / self.sample_period)), 1)\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             y = np.empty((self.batch_size, math.ceil(\n",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "run_experiment_for_electrode_seq2seq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3, 1)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3, 1)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 3, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 3, 200)            320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 3, 1)              201       \n",
      "=================================================================\n",
      "Total params: 482,601\n",
      "Trainable params: 482,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 40s 230ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 39s 226ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode_seq2seq(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3, 1)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3, 1)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 3, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 3, 200)            320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 3, 1)              201       \n",
      "=================================================================\n",
      "Total params: 482,601\n",
      "Trainable params: 482,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 39s 226ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 39s 226ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode_seq2seq(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3, 1)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3, 1)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 200)               161600    \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 3, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 3, 200)            320800    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 3, 1)              201       \n",
      "=================================================================\n",
      "Total params: 482,601\n",
      "Trainable params: 482,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 40s 234ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 38s 219ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode_seq2seq(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
