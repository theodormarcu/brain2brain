{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RepeatedVector' from 'tensorflow.keras.layers' (/home/tmarcu/.conda/envs/brain2brain_env/lib/python3.7/site-packages/tensorflow_core/python/keras/api/_v2/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0630a555782b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepeatedVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# Wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RepeatedVector' from 'tensorflow.keras.layers' (/home/tmarcu/.conda/envs/brain2brain_env/lib/python3.7/site-packages/tensorflow_core/python/keras/api/_v2/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import time\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import redirect_stdout\n",
    "from pathlib import Path\n",
    "# brain2brain\n",
    "from brain2brain import utils\n",
    "from brain2brain import generators\n",
    "# TCN\n",
    "from brain2brain.tcn import TCN\n",
    "from brain2brain.tcn import compiled_tcn\n",
    "# TF\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GRU, Lambda, TimeDistributed, RepeatVector\n",
    "# Wandb\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_for_electrode(electrode = 0):\n",
    "    experiment_dict = {\n",
    "        \"experiment_name\": \"gru_o2o_sweep_676_bin_norm\",\n",
    "        \"experiment_description\" : \"Attempting to predict signals for all electrodes in order to better understand which ones work. All hyperparameters below get passed to hyperparameters_defaults.\",\n",
    "        \"target_folder\" : \"gru_o2o_sweep_676_bin_norm/\",\n",
    "        \"train_path\" : \"/home/tmarcu/brain2brain/brain2brain/train_676_bin_norm_2.txt\",\n",
    "        \"val_path\" : \"/home/tmarcu/brain2brain/brain2brain/val_676_bin_norm_2.txt\",\n",
    "        \"batch_size\" : 512,\n",
    "        \"epochs\" : 128,\n",
    "        \"early_stopping_patience\": 2,\n",
    "        \"lookback_window\" : 15,\n",
    "        \"length_pred\" : 3,\n",
    "        \"delay_pred\" : 0,\n",
    "        \"electrode\" : 0,\n",
    "        \"activation\" : \"relu\",\n",
    "        \"samples_per_second\" : 1,\n",
    "        \"return_sequences\" : True,\n",
    "        \"debug_mode\" : False,\n",
    "        \"hidden_units\": 100,\n",
    "        \"dropout_rate\": 0.05,\n",
    "        \"recurrent_dropout\": 0.05,\n",
    "        \"activation\" : \"linear\",\n",
    "        \"opt\" : \"adam\",\n",
    "        \"loss\" : \"mse\"\n",
    "    }\n",
    "\n",
    "    experiment_name = experiment_dict['experiment_name']\n",
    "    experiment_description = experiment_dict['experiment_description']\n",
    "    target_folder = experiment_dict['target_folder']\n",
    "\n",
    "    # Ensure target directory exists.\n",
    "    try:\n",
    "        Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "    except IOError:\n",
    "        print(f\"Directory creation failed for path {target_folder}\")\n",
    "\n",
    "    # Save dictionary in json as well\n",
    "    utils.save_json_file(experiment_dict, target_folder + \"experiment_params.json\")\n",
    "    # Configure wandb\n",
    "    # Toggle Offline Mode\n",
    "    os.environ['WANDB_MODE'] = 'dryrun'\n",
    "    wandb.init(name=experiment_name,\n",
    "                notes=experiment_description,\n",
    "                config=experiment_dict,\n",
    "                dir=target_folder,\n",
    "                entity=\"theodormarcu\",\n",
    "                project=\"brain2brain\")\n",
    "\n",
    "    # Save Hyperparams\n",
    "    config = wandb.config\n",
    "    # Read saved paths for training.\n",
    "    # saved_paths = utils.get_file_paths(config.path)\n",
    "    train_paths = utils.get_file_paths(config.train_path)\n",
    "    val_paths = utils.get_file_paths(config.val_path)\n",
    "    # Split the train files into a training and validation set.\n",
    "    # train, val = utils.split_file_paths(saved_paths, 0.8)\n",
    "    total_electrode_count = utils.get_file_shape(train_paths[0])[1]\n",
    "    # Electrodes\n",
    "    electrode_count = 1\n",
    "    # Sampling of electrodes.\n",
    "    timesteps_per_sample = int(config.lookback_window // config.samples_per_second)\n",
    "    # Training Generator\n",
    "    train_generator = generators.FGenerator(file_paths=train_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=True,\n",
    "                                            debug=config.debug_mode)\n",
    "    # Validation Generator\n",
    "    val_generator = generators.FGenerator(file_paths=val_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=False,\n",
    "                                            debug=config.debug_mode)\n",
    "\n",
    "    train_steps = len(train_generator)\n",
    "    val_steps = len(val_generator)\n",
    "\n",
    "    print(f\"Train Generator Batch Shape:\\n\"\n",
    "            f\"Sample={train_generator[0][0].shape} Pred={train_generator[0][1].shape}\")\n",
    "    print(f\"Validation Generator Batch Shape:\\n\"\n",
    "            f\"Sample={val_generator[0][0].shape} Pred={val_generator[0][1].shape}\")\n",
    "\n",
    "    callbacks_list = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=2,\n",
    "            mode=\"min\"\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=target_folder+\"model_checkpoint.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        WandbCallback(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_model=True,\n",
    "        )\n",
    "    ]\n",
    "    # GRU One-to-one Architecture\n",
    "    model = Sequential()\n",
    "    model.add(GRU(config.hidden_units,\n",
    "                  activation=config.activation,\n",
    "                  return_sequences=config.return_sequences,\n",
    "                  input_shape=(config.lookback_window, 1),\n",
    "                  dropout=config.dropout_rate,\n",
    "                  recurrent_dropout=config.recurrent_dropout))\n",
    "    print(model.output_shape)\n",
    "    model.add(GRU(config.hidden_units, activation=config.activation))\n",
    "    model.add(Dense(config.length_pred))\n",
    "    model.compile(optimizer=config.opt, loss=config.loss)\n",
    "    model.summary()\n",
    "\n",
    "    # Save Model Config and Architecture\n",
    "    utils.save_json_file(model.get_config(), target_folder + \"model_config.json\")\n",
    "    utils.save_json_file(model.to_json(), target_folder + \"model_architecture.json\")\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                    steps_per_epoch=train_steps,\n",
    "                                    epochs=config.epochs,\n",
    "                                    callbacks=callbacks_list,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=val_steps)\n",
    "\n",
    "    model.save(target_folder + \"model.h5\")\n",
    "    model.save_weights(target_folder + 'model_weights.h5')\n",
    "    # Save History to File (For Later)\n",
    "    utils.save_json_file(history.history, target_folder + \"history.json\")\n",
    "    # Plot Loss Curves for Validation and Training\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "    plt.title(f\"Training and Validation Loss. Electrode {config.electrode}\")\n",
    "    plt.savefig(target_folder + \"train_val_loss_plot.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_28 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 177ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 166ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 33s 188ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 165ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 30s 175ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 169ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 181ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 30s 171ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 181ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 167ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 32s 185ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 28s 164ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 32s 185ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 168ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_22 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 177ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 169ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "(None, 15, 100)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_24 (GRU)                 (None, 15, 100)           30900     \n",
      "_________________________________________________________________\n",
      "gru_25 (GRU)                 (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 91,803\n",
      "Trainable params: 91,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 173 steps, validate for 57 steps\n",
      "Epoch 1/128\n",
      "173/173 [==============================] - 31s 179ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/128\n",
      "173/173 [==============================] - 29s 166ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_for_electrode(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_for_electrode_seq2seq(electrode = 0):\n",
    "    experiment_dict = {\n",
    "        \"experiment_name\": \"gru_o2o_sweep_676_bin_norm_seq2seq\",\n",
    "        \"experiment_description\" : \"Attempting to predict signals for all electrodes in order to better understand which ones work. All hyperparameters below get passed to hyperparameters_defaults.\",\n",
    "        \"target_folder\" : \"gru_o2o_sweep_676_bin_norm_seq2seq/\",\n",
    "        \"train_path\" : \"/home/tmarcu/brain2brain/brain2brain/train_676_bin_norm_2.txt\",\n",
    "        \"val_path\" : \"/home/tmarcu/brain2brain/brain2brain/val_676_bin_norm_2.txt\",\n",
    "        \"batch_size\" : 512,\n",
    "        \"epochs\" : 128,\n",
    "        \"early_stopping_patience\": 2,\n",
    "        \"lookback_window\" : 15,\n",
    "        \"length_pred\" : 3,\n",
    "        \"delay_pred\" : 0,\n",
    "        \"electrode\" : 0,\n",
    "        \"activation\" : \"relu\",\n",
    "        \"samples_per_second\" : 1,\n",
    "        \"return_sequences\" : True,\n",
    "        \"debug_mode\" : False,\n",
    "        \"hidden_units\": 100,\n",
    "        \"dropout_rate\": 0.05,\n",
    "        \"recurrent_dropout\": 0.05,\n",
    "        \"activation\" : \"linear\",\n",
    "        \"opt\" : \"adam\",\n",
    "        \"loss\" : \"mse\"\n",
    "    }\n",
    "\n",
    "    experiment_name = experiment_dict['experiment_name']\n",
    "    experiment_description = experiment_dict['experiment_description']\n",
    "    target_folder = experiment_dict['target_folder']\n",
    "\n",
    "    # Ensure target directory exists.\n",
    "    try:\n",
    "        Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "    except IOError:\n",
    "        print(f\"Directory creation failed for path {target_folder}\")\n",
    "\n",
    "    # Save dictionary in json as well\n",
    "    utils.save_json_file(experiment_dict, target_folder + \"experiment_params.json\")\n",
    "    # Configure wandb\n",
    "    # Toggle Offline Mode\n",
    "    os.environ['WANDB_MODE'] = 'dryrun'\n",
    "    wandb.init(name=experiment_name,\n",
    "                notes=experiment_description,\n",
    "                config=experiment_dict,\n",
    "                dir=target_folder,\n",
    "                entity=\"theodormarcu\",\n",
    "                project=\"brain2brain\")\n",
    "\n",
    "    # Save Hyperparams\n",
    "    config = wandb.config\n",
    "    # Read saved paths for training.\n",
    "    # saved_paths = utils.get_file_paths(config.path)\n",
    "    train_paths = utils.get_file_paths(config.train_path)\n",
    "    val_paths = utils.get_file_paths(config.val_path)\n",
    "    # Split the train files into a training and validation set.\n",
    "    # train, val = utils.split_file_paths(saved_paths, 0.8)\n",
    "    total_electrode_count = utils.get_file_shape(train_paths[0])[1]\n",
    "    # Electrodes\n",
    "    electrode_count = 1\n",
    "    # Sampling of electrodes.\n",
    "    timesteps_per_sample = int(config.lookback_window // config.samples_per_second)\n",
    "    # Training Generator\n",
    "    train_generator = generators.FGenerator(file_paths=train_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=True,\n",
    "                                            debug=config.debug_mode)\n",
    "    # Validation Generator\n",
    "    val_generator = generators.FGenerator(file_paths=val_paths,\n",
    "                                            lookback=config.lookback_window,\n",
    "                                            length=config.length_pred,\n",
    "                                            delay=config.delay_pred,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            sample_period=config.samples_per_second,\n",
    "                                            electrodes=[config.electrode],\n",
    "                                            electrode_output_ix=config.electrode,\n",
    "                                            shuffle=False,\n",
    "                                            debug=config.debug_mode)\n",
    "\n",
    "    train_steps = len(train_generator)\n",
    "    val_steps = len(val_generator)\n",
    "\n",
    "    print(f\"Train Generator Batch Shape:\\n\"\n",
    "            f\"Sample={train_generator[0][0].shape} Pred={train_generator[0][1].shape}\")\n",
    "    print(f\"Validation Generator Batch Shape:\\n\"\n",
    "            f\"Sample={val_generator[0][0].shape} Pred={val_generator[0][1].shape}\")\n",
    "\n",
    "    callbacks_list = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=2,\n",
    "            mode=\"min\"\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=target_folder+\"model_checkpoint.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        WandbCallback(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_model=True,\n",
    "        )\n",
    "    ]\n",
    "    # GRU One-to-one Architecture\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(config.lookback_window, 1)))\n",
    "    model.add(RepeatVector(25))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.summary()\n",
    "\n",
    "    # Save Model Config and Architecture\n",
    "    utils.save_json_file(model.get_config(), target_folder + \"model_config.json\")\n",
    "    utils.save_json_file(model.to_json(), target_folder + \"model_architecture.json\")\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                    steps_per_epoch=train_steps,\n",
    "                                    epochs=config.epochs,\n",
    "                                    callbacks=callbacks_list,\n",
    "                                    validation_data=val_generator,\n",
    "                                    validation_steps=val_steps)\n",
    "\n",
    "    model.save(target_folder + \"model.h5\")\n",
    "    model.save_weights(target_folder + 'model_weights.h5')\n",
    "    # Save History to File (For Later)\n",
    "    utils.save_json_file(history.history, target_folder + \"history.json\")\n",
    "    # Plot Loss Curves for Validation and Training\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "    plt.title(f\"Training and Validation Loss. Electrode {config.electrode}\")\n",
    "    plt.savefig(target_folder + \"train_val_loss_plot.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5429, 114)\n",
      "Train Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n",
      "Validation Generator Batch Shape:\n",
      "Sample=(512, 15, 1) Pred=(512, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RepeatVector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bd99aa253be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_experiment_for_electrode_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-84450c10155a>\u001b[0m in \u001b[0;36mrun_experiment_for_electrode_seq2seq\u001b[0;34m(electrode)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepeatVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RepeatVector' is not defined"
     ]
    }
   ],
   "source": [
    "run_experiment_for_electrode_seq2seq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
