{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import string\n",
    "import json\n",
    "sys.path.append('../')\n",
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import redirect_stdout\n",
    "# brain2brain\n",
    "from brain2brain import utils\n",
    "from brain2brain import generators\n",
    "# TCN\n",
    "from brain2brain.tcn import TCN\n",
    "from brain2brain.tcn import compiled_tcn\n",
    "# TF\n",
    "\n",
    "from tensorflow.keras import backend as K, Model, Input, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GRU, Lambda, TimeDistributed, Activation\n",
    "# import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tmarcu/brain2brain\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"brain2brain/gru_experiment_m2m_1.json\") as f:\n",
    "    experiment_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36853, 114)\n"
     ]
    }
   ],
   "source": [
    "file_prefix = experiment_dict['file_prefix']\n",
    "path = experiment_dict['path']\n",
    "batch_size = experiment_dict['batch_size']\n",
    "epochs = experiment_dict['epochs']\n",
    "lookback_window = experiment_dict['lookback_window']\n",
    "length_pred = experiment_dict['length_pred']\n",
    "delay_pred = experiment_dict['delay_pred']\n",
    "samples_per_second = experiment_dict['samples_per_second']\n",
    "electrode_selection=experiment_dict['electrode_selection']\n",
    "debug_mode = experiment_dict['debug_mode']\n",
    "num_feat = experiment_dict['num_feat']\n",
    "num_classes = experiment_dict['num_classes']\n",
    "nb_filters = experiment_dict['nb_filters']\n",
    "kernel_size = experiment_dict['kernel_size']\n",
    "dilations=experiment_dict['dilations']\n",
    "nb_stacks = experiment_dict['nb_stacks']\n",
    "output_len = experiment_dict['output_len']\n",
    "padding = experiment_dict['padding']\n",
    "use_skip_connections = experiment_dict['use_skip_connections']\n",
    "return_sequences = experiment_dict['return_sequences']\n",
    "regression = experiment_dict['regression']\n",
    "dropout_rate = experiment_dict['dropout_rate']\n",
    "name = experiment_dict['name']\n",
    "kernel_initializer = experiment_dict['kernel_initializer']\n",
    "activation = experiment_dict['activation']\n",
    "opt = experiment_dict['opt']\n",
    "lr = experiment_dict['lr']\n",
    "\n",
    "# Read saved paths for training.\n",
    "saved_paths = utils.get_file_paths(path)\n",
    "# Split the train files into a training and validation set.\n",
    "train, val = utils.split_file_paths(saved_paths, 0.8)\n",
    "total_electrode_count = utils.get_file_shape(train[0])[1]\n",
    "# Electrodes\n",
    "electrode_count = len(electrode_selection)\n",
    "# Sampling of electrodes.\n",
    "timesteps_per_sample = int(lookback_window // samples_per_second)\n",
    "# Training Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Generator\n",
    "train_generator = generators.FGenerator(file_paths=train,\n",
    "                                        lookback=lookback_window, length=length_pred, delay=delay_pred,\n",
    "                                        batch_size=batch_size, sample_period=samples_per_second,\n",
    "                                        electrodes=electrode_selection, shuffle=True, debug=debug_mode)\n",
    "# Validation Generator\n",
    "val_generator = generators.FGenerator(file_paths=val,\n",
    "                                      lookback=lookback_window, length=length_pred, delay=delay_pred,\n",
    "                                      batch_size=batch_size, sample_period=samples_per_second,\n",
    "                                      electrodes=electrode_selection, shuffle=False, debug=debug_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 256, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_generator[0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50225487, 0.59963737, 0.69300725])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 128, 128)          52224     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 128, 6)            774       \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 1, 6)              0         \n",
      "=================================================================\n",
      "Total params: 52,998\n",
      "Trainable params: 52,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "model = Sequential()\n",
    "model.add(GRU(units=timesteps_per_sample,\n",
    "              dropout=0,\n",
    "              recurrent_dropout=0,\n",
    "              input_shape=(timesteps_per_sample, electrode_count),\n",
    "              return_sequences = return_sequences))\n",
    "# model.add(Dense(electrode_count))\n",
    "model.add(TimeDistributed(Dense(electrode_count)))\n",
    "# model.add(Activation(\"linear\"))\n",
    "model.add(Lambda(lambda x: x[:, :length_pred , :]))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss=\"mae\")\n",
    "\n",
    "# Save Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"brain2brain/tcn_experiment_m2m_2.json\") as f:\n",
    "    experiment_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36853, 114)\n"
     ]
    }
   ],
   "source": [
    "file_prefix = experiment_dict['file_prefix']\n",
    "path = experiment_dict['path']\n",
    "batch_size = experiment_dict['batch_size']\n",
    "epochs = experiment_dict['epochs']\n",
    "lookback_window = experiment_dict['lookback_window']\n",
    "length_pred = experiment_dict['length_pred']\n",
    "delay_pred = experiment_dict['delay_pred']\n",
    "samples_per_second = experiment_dict['samples_per_second']\n",
    "electrode_selection=experiment_dict['electrode_selection']\n",
    "debug_mode = experiment_dict['debug_mode']\n",
    "num_feat = experiment_dict['num_feat']\n",
    "num_classes = experiment_dict['num_classes']\n",
    "nb_filters = experiment_dict['nb_filters']\n",
    "kernel_size = experiment_dict['kernel_size']\n",
    "dilations=experiment_dict['dilations']\n",
    "nb_stacks = experiment_dict['nb_stacks']\n",
    "output_len = experiment_dict['output_len']\n",
    "padding = experiment_dict['padding']\n",
    "use_skip_connections = experiment_dict['use_skip_connections']\n",
    "return_sequences = experiment_dict['return_sequences']\n",
    "regression = experiment_dict['regression']\n",
    "dropout_rate = experiment_dict['dropout_rate']\n",
    "name = experiment_dict['name']\n",
    "kernel_initializer = experiment_dict['kernel_initializer']\n",
    "activation = experiment_dict['activation']\n",
    "opt = experiment_dict['opt']\n",
    "lr = experiment_dict['lr']\n",
    "# Read saved paths for training.\n",
    "saved_paths = utils.get_file_paths(path)\n",
    "# Split the train files into a training and validation set.\n",
    "train, val = utils.split_file_paths(saved_paths, 0.8)\n",
    "total_electrode_count = utils.get_file_shape(train[0])[1]\n",
    "# Electrodes\n",
    "electrode_count = len(electrode_selection)\n",
    "# Sampling of electrodes.\n",
    "timesteps_per_sample = int(lookback_window // samples_per_second)\n",
    "# Training Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 5)\n",
      "model.x = (None, 128, 5)\n",
      "model.y = (None, 128, 1)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 128, 5)]          0         \n",
      "_________________________________________________________________\n",
      "tcn_2 (TCN)                  (None, 128, 16)           21904     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128, 1)            17        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 1)            0         \n",
      "=================================================================\n",
      "Total params: 21,921\n",
      "Trainable params: 21,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_opt(opt):\n",
    "    if opt == \"adam\":\n",
    "        return optimizers.Adam(lr=lr, clipnorm=1.0)\n",
    "    elif opt == \"rmsprop\":\n",
    "        return optimizers.RMSprop(lr=lr, clipnorm=1.0)\n",
    "    else:\n",
    "        raise Exception(\"Only Adam and RMSProp are available here.\")\n",
    "\n",
    "\n",
    "# TCN\n",
    "input_layer = Input(shape=(lookback_window, electrode_count))\n",
    "x = TCN(nb_filters=nb_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilations=dilations,\n",
    "        nb_stacks=nb_stacks,\n",
    "        padding=padding,\n",
    "        use_skip_connections=use_skip_connections,\n",
    "        return_sequences=return_sequences,\n",
    "        activation=activation,\n",
    "        dropout_rate=dropout_rate,\n",
    "        kernel_initializer=kernel_initializer)(input_layer)\n",
    "x = TimeDistributed(Dense(electrode_count))(x)\n",
    "x = Lambda(lambda x: x[:, :length_pred , :])(x)\n",
    "# x = Activation('linear')(x)\n",
    "\n",
    "# model.add(Dense(electrode_count))\n",
    "# model.add(TimeDistributed(Dense(electrode_count)))\n",
    "# model.add(Activation(\"linear\"))\n",
    "# model.add(Lambda(lambda x: x[:, :length_pred , :]))\n",
    "output_layer = x\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(get_opt(\"rmsprop\"), loss='mean_absolute_error')\n",
    "\n",
    "print('model.x = {}'.format(input_layer.shape))\n",
    "print('model.y = {}'.format(output_layer.shape))\n",
    "\n",
    "# Save Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
